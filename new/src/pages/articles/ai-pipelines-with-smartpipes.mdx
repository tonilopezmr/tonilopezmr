import { ArticleLayout } from '@/components/ArticleLayout'

export const meta = {
  author: 'Toni LÃ³pez',
  date: '2023-08-09',
  title: 'The AI Framework',
  description:
    'I explain how to build AI Applications in minutes using ML Flows like Smart Pipes Framework',
}

export default (props) => <ArticleLayout meta={meta} {...props} />

Three months ago I won [Generative AI Hackathon in Valencia][1] with an AI Applications builder with a Python SDK.

In the same direction as [Bodia AI][2], I wanted to create an easier way to create AI Applications than Lagnchain and be able to deploy them with a single command.

I began to develop the AI Framework officially for [Seaplane][5] after pivoting into AI.

## ML Flows

Machine Learning Flows determine which steps are included in a machine learning project.
They help you managing the end-to-end ML lifecycles solving [MLOps][3] usually building [DAGs][4].

There are many players that solve this problem but Generative AI.

The idea is to build an ML Flow accessible throught HTTP API Calls, Queues or Cron Jobs.
An ML Flow consist on the Entry Point (`@app`) and different Steps or `@tasks` that scales individually.

```python
@task()
def hello_world_task(data):
    return f"hello world {data['_request_id']}"


@app(id="hello-world-app", path="/hello")
def hello_world_app(data):
    return hello_world_task(data)
```

`@app(id="hello-world-app", path="/hello")`: Is the Entry Point will create an endpoint with Path `/hello`
the DAG is defined in the `@app` body.

`@task()`: Is a single Task that executes a given job, like calling a Generative AI model or Storing anything.

## Smart Pipes AI Framework

Smart Pipes provide many features ready to use in real word AI Applications, like calling Text-to-Text models, 
files as a vectors to embed the text into any Gen AI Model, etc.

The Framework pretend to be the NextJS of Vercel, so you can easily write Web apps and deploy them with a single click.

For example, if you want to load a bunch of files and then create a ChatBot that talks with those files easily:


```python

@app(path="/load_pdfs", id="load_pdfs")
def load_pdfs_app(input):    
    file = save_pdfs(input)    
    store_loaded_file(file)

@task(type="vector", vector_name="my_company_docs")
def save_pdfs(input, store):

    file = input["file"]
    id = store.save(file)

    return {"id": id, "filename": file.filename}

@task(type="sql")
def store_loaded_file(input, sql):

    sql.insert("files_table", input["id], input["filename"])

@task(type="vectordb", vector_name="my_company_docs")
def chat_with_pdfs(input, store):    

    return store.chat(input["query"]) # Returns the answer and the chat history

@app(path="/chatbot", id="files_chatbot")
def save_files(input):
    return chat_with_pdfs(input)

```

With this simple Snippet you have ChatBot that talks with Files, by default It uses `GPT-3.5`, you require to set the OpenAI API Key.

## Trivial deploy

`seaplane deploy` is all you need to deploy your chat bot.

```shell
[Seaplane]

	Seaplane Apps version 0.3.89b2

[Seaplane] Deployed Endpoints:

[Seaplane] ðŸš€ load_pdfs Endpoint: POST /apps/load_pdfs/latest/load_pdfs
[Seaplane] ðŸš€ files_chatbot Endpoint: POST /apps/files_chatbot/latest/chatbot


[Seaplane] ðŸš€ Deployment complete
```

I'll write more about this AI journey, if you are interested on it please let me know on [X @tonilopezmr][6]


[1]: https://www.eventbrite.es/e/generative-ai-hackathon-tickets-619584342447
[2]: https://bodia.ai
[3]: https://en.wikipedia.org/wiki/MLOps
[4]: https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/dags.html
[5]: https://www.seaplane.io/
[6]: https://x.com/tonilopezmr